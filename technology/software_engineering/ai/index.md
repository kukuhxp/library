# ARTIFICIAL INTELLIGENCE

Artificial Intelligence (AI) atau Kecerdasan Buatan adalah cabang dari computer science yang berfokus pada membuat mesin atau program komputer agar dapat berpikir dan bertindak seperti manusia.

## Narrow AI

## String AI

## Machine Learning (ML)

Machine Learning (ML) adalah cabang dari Artificial Intelligence (AI) yang memungkinkan komputer belajar dari data dan membuat keputusan tanpa diprogram secara eksplisit.

Artinya, alih-alih memberi instruksi langkah demi langkah, kita memberi data dan contoh hasil yang benar, lalu komputer belajar sendiri pola di balik data itu untuk membuat keputusan atau prediksi.

Misalnya kamu ingin komputer mengenali apakah gambar berisi kucing atau anjing. Kamu tidak menulis kode deteksi telinga, mata, atau ekor. Kamu cukup memberi banyak contoh gambar kucing dan anjing. Algoritma ML akan mencari pola sendiri seperti bentuk telinga, warna bulu, dll. Setelah belajar, model bisa memprediksi gambar baru yang belum pernah dilihat.

Jenis:

1. Supervised learning, yaitu belajar dari data berlabel.
2. Unsupervised learning, yaitu belajar dari data tanpa label, mencari pola tersembunyi.
3. Reinforcement learning, yaitu belajar dari trial and error melalui reward dan punishment.

Contoh:

1. Rekomendasi di platform Netflix, YouTube atauSpotify.
2. Chatbot & Asisten Virtual, seperti ChatGPT.
3. Deteksi Penipuan di transaksi bank.
4. Self-driving car.
5. Pengenalan wajah dan objek pada gambar.
6. Penerjemahan bahasa otomatis

## Deep Learning

Deep Learning (DL) adalah cabang dari Machine Learning (ML) yang menggunakan Artificial Neuron Network (ANN) berlapis-lapis. Deep learning digunakan untuk memproses data dan membuat keputusan atau prediksi. Deep learning tidak memerlukan campur tangan dari manusia untuk belajar mandiri, tapi memerlukan volume data yang sangat besar agar dapat berjalan optimal.

## Computer Vision (CV)

Computer Vision (CV) adalah cabang dari Artificial Intelligence (AI) yang berfokus pada kemampuan komputer untuk melihat, mengenali, dan memahami gambar atau video seperti halnya manusia menggunakan mata dan otak.

Tujuan utamanya adalah agar komputer bisa mengambil keputusan atau melakukan tindakan berdasarkan informasi visual.

Contoh:

1. Face recognition seperti pada Face ID di smartphone.
2. Self-driving car dapat mengenali rambu lalu lintas, pejalan kaki, dan kendaraan lain.
3. Medical imaging dapat menganalisis hasil rontgen atau MRI untuk mendeteksi penyakit.
4. Object detection dapat mengenali benda seperti manusia, hewan, mobil, atau produk di gambar/video.
5. Optical Character Recognition (OCR) dapat membaca teks dari gambar atau dokumen yang discan.

Tahapan:

1. Input gambar/video ke sistem.
2. Preprocessing untuk membersihkan dan menyesuaikan data.
3. Feature extraction untuk mengambil ciri penting dari gambar (seperti bentuk, tepi, pola).
4. Model Machine Learning / Deep Learning digunakan untuk mengenali atau mengklasifikasikan gambar.
5. Prediksi yang hasilnya bisa berupa label, koordinat objek, atau keputusan tertentu.

## Natural Language Processing (NLP)

Natural Language Processing (NLP) adalah cabang dari Artificial Intelligence (AI) yang berfokus pada interaksi antara komputer dan bahasa manusia. NLP bertujuan agar komputer bisa memahami, menafsirkan, menghasilkan, dan merespons bahasa manusia secara alami.

## Pytorch

## Tensorflow

## Nearest Neighbor Search (NNS)

Nearest Neighbor Search (NNS) adalah proses dalam ilmu komputer dan machine learning untuk mencari data atau titik yang paling mirip, dekat, atau relevan dengan data tertentu, berdasarkan jarak matematis.

## Affective Computing

Affective computing adalah bidang dalam kecerdasan buatan (AI) dan ilmu komputer yang berfokus pada mendeteksi, memahami, meniru, dan merespons emosi manusia melalui teknologi.

## Attention

Attention adalah mekanisme yang membuat model fokus pada bagian penting dari data saat memproses informasi. Setiap data yang dimasukkan akan diubah menjadi 3 vektor, yaitu Query (Q), Key (K) dan Value (V).

Contoh:

Dalam kalimat “Dia makan karena lapar”, model tahu kata “lapar” berkaitan dengan “dia”, bukan “makan”. Jadi, attention membantu AI memahami konteks dan hubungan antar kata agar hasilnya lebih akurat.

## Multi-heas Attention

## Tokenization

Tokenization adalah proses memecah teks menjadi potongan-potongan kecil yang disebut token agar bisa dipahami oleh AI. Token bisa berupa kata, sub-kata, atau bahkan huruf, tergantung modelnya. Tujuannya adalah supaya komputer bisa memproses bahasa manusia dalam bentuk angka (vektor).

Contoh:

Kalimat “Saya suka apel merah.”, diubah menjadi token, menjadi ["Saya", "suka", "apel", "merah", "."]

## Token ID

Token ID adalah nomor unik yang diberikan pada setiap token setelah proses tokenization.

Contoh:

Kalimat “Saya suka apel”, dipecah menjadi token, menjadi ["Saya", "suka", "apel"], lalu diubah menjadi token ID, menjadi [1052, 207, 892]

## Layers

## Embedding Layer

## Embedding Matrix

## Word Embedding

## Byte Pair Encoding (BPE)

Byte Pair Encoding (BPE) adalah algoritma kompresi yang diadaptasi untuk tokenisasi teks dalam model bahasa besar seperti GPT Tujuannya adalah memecah kata menjadi potongan (sub-kata) yang efisien dan tetap bermakna, meskipun model belum pernah melihat kata itu sebelumnya.

## Tiktoken

Tiktoken adalah tokenizer resmi buatan OpenAI, digunakan untuk mengubah teks menjadi token (angka) agar bisa diproses oleh model GPT seperti GPT-3.5 atau GPT-4.

## Vector Database

Vector database adalah jenis basis data khusus yang dirancang untuk menyimpan dan mencari data dalam bentuk vektor.

## Backpropagation

Backpropagation adalah algoritma inti dalam pelatihan neural network. Backpropagation digunakan untuk menghitung dan memperbaiki kesalahan dengan mengubah bobot pada setiap neuron agar model menjadi lebih akurat.

## Stochastic

Stochastic dalam konteks AI adalah algoritma yang mengandung elemen acak untuk membuat keputusan, mempelajari pola, atau mengeksplorasi solusi.

## Deterministic

Deterministic dalam konteks AI adalah algoritma yang selalu memberikan hasil yang sama jika diberikan input yang sama, tanpa unsur acak.

## Temperature

Temperature dalam konteks AI adalah parameter yang mengatur tingkat kreativitas atau keacakan dalam output model.

## Generalized Knowledge Rollover (GKR)

GKR (Generalized Knowledge Rollover) berarti kemampuan sistem untuk membawa pengetahuan umum yang telah dipelajari sebelumnya ke situasi baru, tanpa harus mempelajari semuanya dari awal.
Konsep ini dekat dengan transfer learning, generalization, atau knowledge reuse dalam bidang AI dan cognitive science.

## Inference

inference berarti menggunakan model yang sudah dilatih untuk membuat prediksi atau keputusan baru berdasarkan data input baru. Jadi, training adalah proses belajar model, sedangkan inference adalah proses menggunakan hasil belajar itu.

Contoh:

Model AI sudah dilatih untuk mengenali gambar kucing dan anjing. Saat kamu masukkan gambar baru, proses menentukan apakah itu kucing atau anjing disebut inference.

## Parameter Model

Parameter model adalah nilai-nilai internal di dalam sebuah model yang menentukan bagaimana model tersebut berperilaku dan membuat prediksi. Dengan kata lain, parameter adalah isi otak model yang dipelajari selama proses training. Saat model belajar dari data, ia berusaha menemukan parameter terbaik agar hasil prediksinya paling akurat.

Mereka diubah-ubah selama training sampai hasil prediksi mendekati data sebenarnya. Dalam Model AI seperti ChatGPT, CNN, dll. Model seperti ChatGPT atau GPT-5 memiliki miliaran parameter.
Parameter-parameter ini menyimpan pengetahuan dan pola bahasa yang dipelajari dari data teks selama training.

Semakin banyak parameter, semakin besar kapasitas model bisa memahami konteks dan pola yang lebih kompleks.

Contoh:

1. GPT-2 memiliki 1,5 miliar parameter.
2. GPT-3 memiliki 175 miliar parameter.
3. GPT-4 memiliki >1 triliun parameter.
4. GPT-5 lebih besar lagi.

Jenis:

1. Weights
Mengatur seberapa kuat pengaruh tiap fitur input terhadap output.

2. Biases
Nilai tambahan agar model bisa menggeser hasil tanpa mengubah input.

3. Embedding Weights
Digunakan untuk merepresentasikan kata atau simbol ke dalam bentuk vektor angka.

## Context Window

Context window atau jendela konteks adalah jumlah token yang bisa diingat dan diproses oleh model dalam satu waktu percakapan. Context window mencakup pesan dari pengguna, jawaban model sebelumnya, sistem prompt, informasi tambahan.

Contoh:

Misal sebuah model punya context window 8.000 token, berarti model hanya bisa melihat dan memahami 8.000 token terakhir dari percakapan atau teks yang kamu kirim. Jika percakapan melewati batas itu, bagian paling awal akan tergeser keluar dari jendela konteks.

## Chain Rule of Probability

## Byte Pair Encoding (BPE)

## Top-k

## Top-p

## Subword Tokenization

## Positional encoding

## Stacked Transformer blocks

## Softmax

## Tokenizer

## Model Context Protocol (MCP)

Model Context Protocol (MCP) adalah protokol terbuka yang dikembangkan oleh Anthropic untuk menyederhanakan integrasi antara model bahasa besar (LLM) dan berbagai sumber data serta alat eksternal. MCP memungkinkan AI untuk mengakses, memahami, dan berinteraksi dengan data secara real-time, sehingga meningkatkan kemampuan AI dalam menjalankan tugas-tugas kompleks
