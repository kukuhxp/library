# ARTIFICIAL INTELLIGENCE

Artificial Intelligence (AI) atau Kecerdasan Buatan adalah cabang dari ilmu komputer yang berfokus pada membuat mesin atau program komputer agar dapat berpikir dan bertindak seperti manusia.

## Machine Learning (ML)

Machine Learning (ML) adalah cabang dari kecerdasan buatan yang memungkinkan komputer belajar dari data dan membuat keputusan tanpa diprogram secara eksplisit. Ada beberapa jenis dari machine learning, yaitu:

- Supervised Learning
- Unsupervised Learning
- Reinforcement Learning

## Neural Network

Neural network atau jaringan saraf tiruan adalah sebuah metode dalam kecerdasan buatan (AI) yang meniru cara kerja otak manusia dalam memproses informasi. Ada beberapa jenis dari neural network, diantaranya adalah:

1. Feedforward Neural Network (FNN)
2. Convolutional Neural Network (CNN)
3. Recurrent Neural Network (RNN)
4. Long Short-term Memory (LSTM)
5. Gated Recurrent Unit (GRU)
6. Radial Basis Function Network (RBFN)
7. Generative Adversarial Network (GAN)
8. Auto-encoder
9. Transformer
10. Modular Neural Network (MNN)

## Deep Learning

Deep learning adalah cabang dari machine learning yang menggunakan jaringan saraf tiruan berlapis-lapis. Deep learning digunakan untuk memproses data dan membuat keputusan atau prediksi.

## Nearest Neighbor Search (NNS)

Nearest Neighbor Search (NNS) adalah proses dalam ilmu komputer dan machine learning untuk mencari data atau titik yang paling mirip, dekat, atau relevan dengan data tertentu, berdasarkan jarak matematis (misalnya Euclidean, Manhattan, cosine similarity, dll).

## Affective Computing

Affective computing adalah bidang dalam kecerdasan buatan (AI) dan ilmu komputer yang berfokus pada mendeteksi, memahami, meniru, dan merespons emosi manusia melalui teknologi.

## Large Language Models (LLM)

Large Language Models (LLM) adalah jenis model kecerdasan buatan (AI) yang dilatih untuk memahami dan menghasilkan teks dalam bahasa manusia dengan tingkat pemahaman yang sangat tinggi.

## Transformer

Transformer adalah arsitektur model neural network yang menjadi dasar dari banyak sistem kecerdasan buatan modern, termasuk ChatGPT, GPT, BERT, dan lain-lain.

## Attention

Attention adalah mekanisme yang membuat model fokus pada bagian penting dari data saat memproses informasi.

Contohnya, dalam kalimat “Dia makan karena lapar”, model tahu kata “lapar” berkaitan dengan “dia”, bukan “makan”.
Jadi, attention membantu AI memahami konteks dan hubungan antar kata agar hasilnya lebih akurat.

## Tokenization

Tokenization adalah proses memecah teks menjadi potongan-potongan kecil yang disebut token agar bisa dipahami oleh AI.

Contoh:
Kalimat → “Saya suka apel merah.”
Token → ["Saya", "suka", "apel", "merah", "."]

Token bisa berupa kata, sub-kata, atau bahkan huruf, tergantung modelnya.
Tujuannya: supaya komputer bisa memproses bahasa manusia dalam bentuk angka (vektor).

## Token ID

Token ID adalah nomor unik yang diberikan pada setiap token setelah proses tokenization.

Contoh:
Kalimat → “Saya suka apel”
Token → ["Saya", "suka", "apel"]
Token ID → [1052, 207, 892] (contoh saja)

Jadi, Token ID = versi angka dari token, agar model AI bisa memprosesnya secara matematis.

Singkatnya:
Teks → Token → Token ID → Diproses oleh model.

## Byte Pair Encoding (BPE)

Byte Pair Encoding (BPE) adalah algoritma kompresi yang diadaptasi untuk tokenisasi teks dalam model bahasa besar seperti GPT Tujuannya adalah memecah kata menjadi potongan (sub-kata) yang efisien dan tetap bermakna, meskipun model belum pernah melihat kata itu sebelumnya.

## Tiktoken

Tiktoken adalah tokenizer resmi buatan OpenAI, digunakan untuk mengubah teks menjadi token (angka) agar bisa diproses oleh model GPT seperti GPT-3.5 atau GPT-4.

## Vector Database

Vector database adalah jenis basis data khusus yang dirancang untuk menyimpan dan mencari data dalam bentuk vektor.

## Computer Vision (CV)

Computer Vision (CV) adalah cabang dari kecerdasan buatan (AI) yang berfokus pada membuat komputer bisa melihat, memahami, dan mengambil keputusan.

## Natural Language Processing (NLP)

Natural Language Processing (NLP) adalah cabang dari kecerdasan buatan (AI) yang berfokus pada interaksi antara komputer dan bahasa manusia. NLP bertujuan agar komputer bisa memahami, menafsirkan, menghasilkan, dan merespons bahasa manusia secara alami.

## Backpropagation

Backpropagation adalah algoritma inti dalam pelatihan neural network. Backpropagation digunakan untuk menghitung dan memperbaiki kesalahan dengan mengubah bobot pada setiap neuron agar model menjadi lebih akurat.

## Stochastic

Stochastic dalam konteks AI adalah algoritma yang mengandung elemen acak untuk membuat keputusan, mempelajari pola, atau mengeksplorasi solusi.

## Deterministic

Deterministic dalam konteks AI adalah algoritma yang selalu memberikan hasil yang sama jika diberikan input yang sama, tanpa unsur acak.

## Temperature

Temperature dalam konteks AI adalah parameter yang mengatur tingkat kreativitas atau keacakan dalam output model.

## Generalized Knowledge Rollover (GKR)

GKR (Generalized Knowledge Rollover) berarti kemampuan sistem untuk membawa pengetahuan umum yang telah dipelajari sebelumnya ke situasi baru, tanpa harus mempelajari semuanya dari awal.
Konsep ini dekat dengan transfer learning, generalization, atau knowledge reuse dalam bidang AI dan cognitive science.